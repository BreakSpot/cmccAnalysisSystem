## 去哪儿“当季热门度假”实时分析监控平台



### 项目背景：

​	越来越多的旅游人群选择使用“去哪儿”，我们提供国内外特价机票，酒店，旅游度假，景点门票产品一站式预订服务，提供实时的热门旅游景点，给用户提供最好的体验。

​	为了之后更好的运营和对各个模块进行积极的调整，我公司对各城市旅游情况进行统计，解决数据量大，数据内容复杂繁多，对服务器造成的压力大的问题，需要我部门开发实时分析监控平台，对大量的数据进行处理，从订单量，浏览量，成交量等等指标，掌控全网的用户旅游流向，为公司运营提供便利

### 项目流程：



### 技术选型：

flume：配置相关

 agent.sources.s1.type=exec 	

 agent.sources.s1.command=tail -F /root/log/cmcc.log 

 #设置一个kafka接收器       

 agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink        

#设置kafka的broker地址和端口号(所有的) 

agent.sinks.k1.brokerList=hadoop01:9092,hadoop02:9092,hadoop03:9092

#设置kafka的topic        

agent.sinks.k1.topic=cmcc2 

kafka：

sparkStreaming：一次仅一次，保证数据安全性，操作简单，易于运维人员维护，吞吐量高

### 参与的模块

实时处理订单模块：

实时统计全网的订单量，订单金额，订单交易成功数

实时统计交易办理趋势，主要统计全网的订单量数据

统计每小时各个旅游景点的交易成功数据量

以省份为维度统计订单量排名前 10 的省份数据，并且统计每个省份的订单成功率

实时统计每小时的订单成功笔数和订单总金额。

### 遇到的问题

保证在宕机的情况下如何做到，不重复保存数据。

解决方法：手动维护offset的同时，做到数据库的幂等性+读取checkpoint

kafka数据积压

ERROR [2017-01-12 07:16:02,466] com.flow.kafka.consumer.main.KafkaConsumer: Unexpected Error Occurred
! kafka.common.MessageSizeTooLargeException: Found a message larger than the maximum fetch size of this consumer on topic codeTopic partition 3 at fetch offset 94. Increase the fetch size, or decrease the maximum message size the broker will allow.

1. 减小broker消息体大小(设置message.max.bytes参数)；
2. 增大consumer获取数据信息大小(设置fetch.message.max.bytes参数)。默认broker消息体大小为1000000字节即为1M大小。把consumer程序的fetch.message.max.bytes参数调节为了3072000即为3M，重启consumer程序，查看log一切正常，解决这个消费错误到此结束，kafka在消息为10K时吞吐量达到最大

### 项目优化

日志存入Hbase



### 集群大小和数据量

业务节点分为 PC 端和手机端:

PC 端一共有 11 台, flume 会监控每台节点生成的日志文件, 一共有 11 个 Flume 节点手机端一共有 8 台,flume 会监控每台节点生成的日志文件, 一共有 8 个 Flume 节点.

支付结果通知和充值结果通知:

该业务有 4 台节点, flume 会监控每台节点生成的日志文件, 一共有 4 个 Flume 节点. 机器配置?
数据量每天大概：
2000 到 3000 万笔的下单量, 每条数据大概在 0.5KB 左右,下单量数据大概在 15GB 左右.

### 数据存储

mysql

redis
